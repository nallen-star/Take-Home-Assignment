{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da2a71ba-38b3-41e7-a120-44d657ec8966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/klaus/Desktop/MSBA - 503/images/clark_bball.webp: 384x640 8 persons, 96.0ms\n",
      "Speed: 2.7ms preprocess, 96.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /Users/klaus/Desktop/MSBA - 503/images/dupont.jpg: 352x640 11 persons, 2 sports balls, 101.9ms\n",
      "Speed: 1.8ms preprocess, 101.9ms inference, 0.7ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "image 1/1 /Users/klaus/Desktop/MSBA - 503/images/kai.webp: 448x640 2 persons, 1 bottle, 96.2ms\n",
      "Speed: 4.3ms preprocess, 96.2ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /Users/klaus/Desktop/MSBA - 503/images/big_ears.webp: 448x640 1 cat, 69.9ms\n",
      "Speed: 2.3ms preprocess, 69.9ms inference, 0.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /Users/klaus/Desktop/MSBA - 503/images/united.jpg: 448x640 1 airplane, 89.2ms\n",
      "Speed: 3.1ms preprocess, 89.2ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /Users/klaus/Desktop/MSBA - 503/images/sports_fan.jpeg: 384x640 4 persons, 86.7ms\n",
      "Speed: 2.8ms preprocess, 86.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /Users/klaus/Desktop/MSBA - 503/images/chair.jpg: 640x640 2 chairs, 1 potted plant, 124.8ms\n",
      "Speed: 5.6ms preprocess, 124.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/klaus/Desktop/MSBA - 503/images/fruit.jpg: 448x640 1 carrot, 1 dining table, 87.9ms\n",
      "Speed: 2.9ms preprocess, 87.9ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /Users/klaus/Desktop/MSBA - 503/images/sandiego.jpg: 512x640 2 persons, 15 cars, 1 traffic light, 97.5ms\n",
      "Speed: 2.9ms preprocess, 97.5ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "image 1/1 /Users/klaus/Desktop/MSBA - 503/images/dogs.webp: 384x640 9 dogs, 93.8ms\n",
      "Speed: 2.8ms preprocess, 93.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Image</th>\n",
       "      <th>Objects Detected</th>\n",
       "      <th>Avg Confidence</th>\n",
       "      <th>Time (sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YOLOv8</td>\n",
       "      <td>clark_bball.webp</td>\n",
       "      <td>8</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.1417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YOLOv8</td>\n",
       "      <td>dupont.jpg</td>\n",
       "      <td>13</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.1126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>YOLOv8</td>\n",
       "      <td>kai.webp</td>\n",
       "      <td>3</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.1132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YOLOv8</td>\n",
       "      <td>big_ears.webp</td>\n",
       "      <td>1</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>YOLOv8</td>\n",
       "      <td>united.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>YOLOv8</td>\n",
       "      <td>sports_fan.jpeg</td>\n",
       "      <td>4</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>YOLOv8</td>\n",
       "      <td>chair.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.1605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>YOLOv8</td>\n",
       "      <td>fruit.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.2485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>YOLOv8</td>\n",
       "      <td>sandiego.jpg</td>\n",
       "      <td>18</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.2407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>YOLOv8</td>\n",
       "      <td>dogs.webp</td>\n",
       "      <td>9</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.1078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model             Image  Objects Detected  Avg Confidence  Time (sec)\n",
       "0  YOLOv8  clark_bball.webp                 8           0.625      0.1417\n",
       "1  YOLOv8        dupont.jpg                13           0.559      0.1126\n",
       "2  YOLOv8          kai.webp                 3           0.773      0.1132\n",
       "3  YOLOv8     big_ears.webp                 1           0.656      0.1349\n",
       "4  YOLOv8        united.jpg                 1           0.923      0.1050\n",
       "5  YOLOv8   sports_fan.jpeg                 4           0.542      0.1001\n",
       "6  YOLOv8         chair.jpg                 3           0.796      0.1605\n",
       "7  YOLOv8         fruit.jpg                 2           0.512      0.2485\n",
       "8  YOLOv8      sandiego.jpg                18           0.540      0.2407\n",
       "9  YOLOv8         dogs.webp                 9           0.850      0.1078"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "image_folder = \"images\"\n",
    "valid_ext = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\", \".webp\")\n",
    "\n",
    "results_data = []\n",
    "\n",
    "for img_name in os.listdir(image_folder):\n",
    "    if not img_name.lower().endswith(valid_ext):\n",
    "        continue   # âœ… skips .DS_Store and any non-image files\n",
    "\n",
    "    img_path = os.path.join(image_folder, img_name)\n",
    "\n",
    "    start = time.time()\n",
    "    results = model(img_path)\n",
    "    end = time.time()\n",
    "\n",
    "    detections = results[0].boxes\n",
    "    objects = len(detections)\n",
    "    avg_conf = float(detections.conf.mean()) if objects > 0 else 0\n",
    "\n",
    "    results_data.append({\n",
    "        \"Model\": \"YOLOv8\",\n",
    "        \"Image\": img_name,\n",
    "        \"Objects Detected\": objects,\n",
    "        \"Avg Confidence\": round(avg_conf, 3),\n",
    "        \"Time (sec)\": round(end - start, 4)\n",
    "    })\n",
    "\n",
    "df_yolo = pd.DataFrame(results_data)\n",
    "df_yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba402023-2a85-46c8-af78-850684d3fbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tf/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/tf/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.transforms import functional as F\n",
    "from PIL import Image\n",
    "\n",
    "# Load pre-trained Faster R-CNN\n",
    "frcnn_model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "frcnn_model.eval()\n",
    "\n",
    "frcnn_results_data = []\n",
    "\n",
    "for img_name in os.listdir(image_folder):\n",
    "    if not img_name.lower().endswith(valid_ext):\n",
    "        continue\n",
    "\n",
    "    img_path = os.path.join(image_folder, img_name)\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    img_tensor = F.to_tensor(img)\n",
    "\n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "        outputs = frcnn_model([img_tensor])\n",
    "    end = time.time()\n",
    "\n",
    "    boxes = outputs[0]['boxes']\n",
    "    scores = outputs[0]['scores']\n",
    "    objects = len(boxes)\n",
    "    avg_conf = float(scores.mean()) if objects > 0 else 0\n",
    "\n",
    "    frcnn_results_data.append({\n",
    "        \"Model\": \"Faster-RCNN\",\n",
    "        \"Image\": img_name,\n",
    "        \"Objects Detected\": objects,\n",
    "        \"Avg Confidence\": round(avg_conf, 3),\n",
    "        \"Time (sec)\": round(end - start, 4)\n",
    "    })\n",
    "\n",
    "df_frcnn = pd.DataFrame(frcnn_results_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca4d0277-6903-4460-93a8-ac5bb4f8c787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Model             Image  Objects Detected  Avg Confidence  \\\n",
      "0        YOLOv8  clark_bball.webp                 8           0.625   \n",
      "1        YOLOv8        dupont.jpg                13           0.559   \n",
      "2        YOLOv8          kai.webp                 3           0.773   \n",
      "3        YOLOv8     big_ears.webp                 1           0.656   \n",
      "4        YOLOv8        united.jpg                 1           0.923   \n",
      "5        YOLOv8   sports_fan.jpeg                 4           0.542   \n",
      "6        YOLOv8         chair.jpg                 3           0.796   \n",
      "7        YOLOv8         fruit.jpg                 2           0.512   \n",
      "8        YOLOv8      sandiego.jpg                18           0.540   \n",
      "9        YOLOv8         dogs.webp                 9           0.850   \n",
      "10  Faster-RCNN  clark_bball.webp               100           0.431   \n",
      "11  Faster-RCNN        dupont.jpg                55           0.355   \n",
      "12  Faster-RCNN          kai.webp                29           0.284   \n",
      "13  Faster-RCNN     big_ears.webp                11           0.206   \n",
      "14  Faster-RCNN        united.jpg                 1           1.000   \n",
      "15  Faster-RCNN   sports_fan.jpeg                46           0.288   \n",
      "16  Faster-RCNN         chair.jpg                15           0.395   \n",
      "17  Faster-RCNN         fruit.jpg                42           0.295   \n",
      "18  Faster-RCNN      sandiego.jpg                93           0.451   \n",
      "19  Faster-RCNN         dogs.webp                21           0.521   \n",
      "\n",
      "    Time (sec)  \n",
      "0       0.1417  \n",
      "1       0.1126  \n",
      "2       0.1132  \n",
      "3       0.1349  \n",
      "4       0.1050  \n",
      "5       0.1001  \n",
      "6       0.1605  \n",
      "7       0.2485  \n",
      "8       0.2407  \n",
      "9       0.1078  \n",
      "10      2.9595  \n",
      "11      2.6732  \n",
      "12      2.7054  \n",
      "13      2.8343  \n",
      "14      2.6641  \n",
      "15      2.8162  \n",
      "16      1.9584  \n",
      "17      2.8978  \n",
      "18      2.4425  \n",
      "19      2.8479  \n"
     ]
    }
   ],
   "source": [
    "df_comparison = pd.concat([df_yolo, df_frcnn], ignore_index=True)\n",
    "print(df_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7cc6d10b-c160-425e-b392-08d3c7a0bd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Image  Width  Height           Avg Color (BGR)\n",
      "0  clark_bball.webp    640     360     [72.92, 67.84, 73.06]\n",
      "1        dupont.jpg   1050     550    [75.64, 118.36, 99.67]\n",
      "2          kai.webp    942     628     [41.81, 47.04, 55.65]\n",
      "3     big_ears.webp   2500    1667   [86.99, 124.24, 178.22]\n",
      "4        united.jpg   1024     683  [171.87, 142.31, 115.57]\n",
      "5   sports_fan.jpeg   1000     562     [86.84, 96.2, 142.55]\n",
      "6         chair.jpg   1500    1500  [131.59, 153.43, 172.55]\n",
      "7         fruit.jpg   4000    2667     [59.4, 89.09, 106.08]\n",
      "8      sandiego.jpg   2560    1965   [72.78, 101.59, 147.77]\n",
      "9         dogs.webp    520     291  [135.13, 150.53, 168.51]\n"
     ]
    }
   ],
   "source": [
    "additional_data = []\n",
    "\n",
    "for img_name in os.listdir(image_folder):\n",
    "    if not img_name.lower().endswith(valid_ext):\n",
    "        continue\n",
    "\n",
    "    img_path = os.path.join(image_folder, img_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    h, w, c = img.shape\n",
    "    avg_color = img.mean(axis=(0,1))\n",
    "\n",
    "    additional_data.append({\n",
    "        \"Image\": img_name,\n",
    "        \"Width\": w,\n",
    "        \"Height\": h,\n",
    "        \"Avg Color (BGR)\": avg_color.round(2)\n",
    "    })\n",
    "\n",
    "df_additional = pd.DataFrame(additional_data)\n",
    "print(df_additional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fddcd6b-a6a3-4924-8bb5-fa63cf129daa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf - TensorFlow)",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
